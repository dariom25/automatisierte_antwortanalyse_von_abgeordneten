{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix encoding problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"data/abgeordnetenwatch_data_long.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46018"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data.dropna(subset=\"answer\")\n",
    "df_data = df_data.drop_duplicates(subset=[\"answer\", \"question_text\"])\n",
    "len(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_csv(\"data/stratified_sample.csv\", sep=\";\")\n",
    "df_sample = df_sample.drop_duplicates(subset=[\"answer\", \"question_text\"])\n",
    "df_sample = df_sample.dropna(subset=[\"answer\", \"answer_encoded\"])\n",
    "len(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_data, df_sample, on=\"question_id\", how=\"left\")\n",
    "df_merged = df_merged[[\"party_x\", \"last_name_x\", \"gender_x\", \"answer_x\", \"topic_x\", \"question_text_x\", \"question_teaser_x\", \"answer_encoded\"]]\n",
    "df_merged = df_merged.dropna(subset=\"answer_encoded\")\n",
    "df_merged.rename(columns={\n",
    "    \"party_x\" : \"party\",\n",
    "    \"last_name_x\" : \"last_name\",\n",
    "    \"gender_x\" : \"gender\",\n",
    "    \"answer_x\" : \"answer\",\n",
    "    \"topic_x\" : \"topic\",\n",
    "    \"question_text_x\" : \"question_text\",\n",
    "    \"question_teaser_x\" : \"question_teaser\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def text_lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_punct]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # remove links, punctuation, special letters\n",
    "    text = re.sub(r\"[^a-zA-öZÖäÄüÜß]|\\bhttps?://\\S*|&\\w+;|[\\.,]\", \" \", text)\n",
    "    \n",
    "    # replace single characters\n",
    "    text = re.sub(r\" [a-zA-Z] \", \" \", text)\n",
    "    \n",
    "    # remove additional whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lemmatize texts\n",
    "    text = text_lemmatization(text)\n",
    "\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # tokenization of words\n",
    "    text = text.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    german_stopwords = set(stopwords.words(\"german\"))\n",
    "    text = [w for w in text if w not in german_stopwords]\n",
    "    \n",
    "    # return joined text\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"clean_answer\"] = df_merged[\"answer\"].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequencies</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>1</td>\n",
       "      <td>konstatieren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>1</td>\n",
       "      <td>guthmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>1</td>\n",
       "      <td>schulablauf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>1</td>\n",
       "      <td>gutsituiert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>1</td>\n",
       "      <td>gvfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>1</td>\n",
       "      <td>gymnasial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>1</td>\n",
       "      <td>schui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>1</td>\n",
       "      <td>gymnasie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16901</th>\n",
       "      <td>1</td>\n",
       "      <td>schuhmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>1</td>\n",
       "      <td>gymnasium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16900</th>\n",
       "      <td>1</td>\n",
       "      <td>schubert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>1</td>\n",
       "      <td>gutenmut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>1</td>\n",
       "      <td>gähnend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16897</th>\n",
       "      <td>1</td>\n",
       "      <td>schröter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16894</th>\n",
       "      <td>1</td>\n",
       "      <td>schrumpfen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>1</td>\n",
       "      <td>gärtner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157</th>\n",
       "      <td>1</td>\n",
       "      <td>gäubahn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9158</th>\n",
       "      <td>1</td>\n",
       "      <td>gönül</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16890</th>\n",
       "      <td>1</td>\n",
       "      <td>schriftsteller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>1</td>\n",
       "      <td>görtz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequencies           index\n",
       "11577            1    konstatieren\n",
       "9139             1        guthmann\n",
       "16904            1     schulablauf\n",
       "9141             1     gutsituiert\n",
       "9142             1            gvfg\n",
       "9144             1       gymnasial\n",
       "16902            1           schui\n",
       "9146             1        gymnasie\n",
       "16901            1       schuhmann\n",
       "9148             1       gymnasium\n",
       "16900            1        schubert\n",
       "9137             1        gutenmut\n",
       "9150             1         gähnend\n",
       "16897            1        schröter\n",
       "16894            1      schrumpfen\n",
       "9156             1         gärtner\n",
       "9157             1         gäubahn\n",
       "9158             1           gönül\n",
       "16890            1  schriftsteller\n",
       "9160             1           görtz"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show most frequent words\n",
    "vectorizer = CountVectorizer(\n",
    ")\n",
    "dtm = vectorizer.fit_transform(df_merged[\"clean_answer\"])\n",
    "\n",
    "frequencies = dtm.sum(axis=0).tolist()[0]\n",
    "\n",
    "df_freq = pd.DataFrame(\n",
    "    dict(frequencies=frequencies,\n",
    "         index=vectorizer.get_feature_names_out()\n",
    "    )\n",
    ")\n",
    "\n",
    "df_freq.sort_values(\"frequencies\", ascending=True).head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords with refined list and after lemmatization to catch \n",
    "def remove_individual_stopwords(text):\n",
    "    individual_stopwords = [\n",
    "        \"geehrt\",\n",
    "        \"frau\",\n",
    "        \"vieler\",\n",
    "        \"dank\",\n",
    "        \"herr\",\n",
    "        \"danke\",\n",
    "        \"anfrage\",\n",
    "        \"frage\",\n",
    "        \"nachricht\",\n",
    "        \"freundlich\",\n",
    "        \"sollen\",\n",
    "        \"müssen\",\n",
    "        \"mehr\",\n",
    "        \"grüße\",\n",
    "        \"daher\",\n",
    "        \"immer\",\n",
    "        \"dafür\"\n",
    "    ]\n",
    "    text = text.split()\n",
    "    text = [w for w in text if w not in individual_stopwords]\n",
    "    \n",
    "    return \" \".join(text)\n",
    "\n",
    "df_merged[\"clean_answer\"] = df_merged[\"clean_answer\"].apply(remove_individual_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43       name person groß bedeutung eigen identität ind...\n",
       "68       bürokratiekostenindex wichtig maß erfassung bü...\n",
       "106      namensrecht bundestag änderung ehenamen geburt...\n",
       "112      eckpunktepapier reform abstammungsrecht veröff...\n",
       "143      seit anfang unionsbürgerinn unionsbürger sowie...\n",
       "                               ...                        \n",
       "45894    verhandlungsbereitschaft erkennbar gegenteil h...\n",
       "45924    natürlich michael bloss gesetz wiederherstellu...\n",
       "45945    genau beschreiben kontrolle bedeuten direkt ko...\n",
       "45974    frei demokrat stehen freiheit einzeln mensch v...\n",
       "45988    nature restoration law letzter woche europäisc...\n",
       "Name: clean_answer, Length: 1686, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"clean_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data for fasttext\n",
    "df_merged[\"answer_encoded\"] = df_merged[\"answer_encoded\"].apply(lambda x: x.replace(\" \", \"_\"))\n",
    "df_merged[\"answer_encoded\"] = df_merged[\"answer_encoded\"].apply(lambda x: \"__label__\" + x)\n",
    "df_merged[\"answer_encoding_combined\"] = df_merged[\"answer_encoded\"]+ \" \" + df_merged[\"clean_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "df_merged.to_csv(\"data/stratified_sample_cleaned.csv\", index=False, sep=\";\", )\n",
    "df_merged[\"answer_encoding_combined\"].to_csv(\"data/fasttext_data.csv\", sep=\";\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
