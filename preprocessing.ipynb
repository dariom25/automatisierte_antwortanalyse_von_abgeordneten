{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix encoding problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"data/abgeordnetenwatch_data_long.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46018"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data.dropna(subset=\"answer\")\n",
    "df_data = df_data.drop_duplicates(subset=[\"answer\", \"question_text\"])\n",
    "len(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_csv(\"data/stratified_sample.csv\", sep=\";\")\n",
    "df_sample = df_sample.drop_duplicates(subset=[\"answer\", \"question_text\"])\n",
    "df_sample = df_sample.dropna(subset=[\"answer\", \"answer_encoded\"])\n",
    "len(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_data, df_sample, on=\"question_id\", how=\"left\")\n",
    "df_merged = df_merged[[\"party_x\", \"last_name_x\", \"gender_x\", \"answer_x\", \"topic_x\", \"question_text_x\", \"question_teaser_x\", \"answer_encoded\"]]\n",
    "df_merged = df_merged.dropna(subset=\"answer_encoded\")\n",
    "df_merged.rename(columns={\n",
    "    \"party_x\" : \"party\",\n",
    "    \"last_name_x\" : \"last_name\",\n",
    "    \"gender_x\" : \"gender\",\n",
    "    \"answer_x\" : \"answer\",\n",
    "    \"topic_x\" : \"topic\",\n",
    "    \"question_text_x\" : \"question_text\",\n",
    "    \"question_teaser_x\" : \"question_teaser\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def text_lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_punct]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # remove links, punctuation, special letters\n",
    "    text = re.sub(r\"[^a-zA-öZÖäÄüÜß]|\\bhttps?://\\S*|&\\w+;|[\\.,]\", \" \", text)\n",
    "    \n",
    "    # replace single characters\n",
    "    text = re.sub(r\" [a-zA-Z] \", \" \", text)\n",
    "    \n",
    "    # remove additional whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lemmatize texts\n",
    "    text = text_lemmatization(text)\n",
    "\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # tokenization of words\n",
    "    text = text.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    german_stopwords = set(stopwords.words(\"german\"))\n",
    "    text = [w for w in text if w not in german_stopwords]\n",
    "    \n",
    "    # return joined text\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"clean_answer\"] = df_merged[\"answer\"].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequencies</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>1</td>\n",
       "      <td>konstituiert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9138</th>\n",
       "      <td>1</td>\n",
       "      <td>gymnasium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16895</th>\n",
       "      <td>1</td>\n",
       "      <td>schulbereich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>1</td>\n",
       "      <td>gähnend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16894</th>\n",
       "      <td>1</td>\n",
       "      <td>schulbedarf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16893</th>\n",
       "      <td>1</td>\n",
       "      <td>schulausschuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16892</th>\n",
       "      <td>1</td>\n",
       "      <td>schulaufgab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16891</th>\n",
       "      <td>1</td>\n",
       "      <td>schulalltag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>1</td>\n",
       "      <td>gärtner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>1</td>\n",
       "      <td>gäubahn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>1</td>\n",
       "      <td>gönül</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16896</th>\n",
       "      <td>1</td>\n",
       "      <td>schulbesuch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16889</th>\n",
       "      <td>1</td>\n",
       "      <td>schulablauf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9151</th>\n",
       "      <td>1</td>\n",
       "      <td>göteborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>1</td>\n",
       "      <td>götz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154</th>\n",
       "      <td>1</td>\n",
       "      <td>gößling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>1</td>\n",
       "      <td>güllemass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16887</th>\n",
       "      <td>1</td>\n",
       "      <td>schui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16886</th>\n",
       "      <td>1</td>\n",
       "      <td>schuhmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>1</td>\n",
       "      <td>schubert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequencies           index\n",
       "11569            1    konstituiert\n",
       "9138             1       gymnasium\n",
       "16895            1    schulbereich\n",
       "9140             1         gähnend\n",
       "16894            1     schulbedarf\n",
       "16893            1  schulausschuss\n",
       "16892            1     schulaufgab\n",
       "16891            1     schulalltag\n",
       "9146             1         gärtner\n",
       "9147             1         gäubahn\n",
       "9148             1           gönül\n",
       "16896            1     schulbesuch\n",
       "16889            1     schulablauf\n",
       "9151             1        göteborg\n",
       "9153             1            götz\n",
       "9154             1         gößling\n",
       "9155             1       güllemass\n",
       "16887            1           schui\n",
       "16886            1       schuhmann\n",
       "16885            1        schubert"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show most frequent words\n",
    "vectorizer = CountVectorizer(\n",
    ")\n",
    "dtm = vectorizer.fit_transform(df_merged[\"clean_answer\"])\n",
    "\n",
    "frequencies = dtm.sum(axis=0).tolist()[0]\n",
    "\n",
    "df_freq = pd.DataFrame(\n",
    "    dict(frequencies=frequencies,\n",
    "         index=vectorizer.get_feature_names_out()\n",
    "    )\n",
    ")\n",
    "\n",
    "df_freq.sort_values(\"frequencies\", ascending=True).head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords with refined list and after lemmatization to catch \n",
    "def remove_individual_stopwords(text):\n",
    "    individual_stopwords = [\n",
    "        \"geehrt\",\n",
    "        \"frau\",\n",
    "        \"vieler\",\n",
    "        \"dank\",\n",
    "        \"herr\",\n",
    "        \"danke\",\n",
    "        \"anfrage\",\n",
    "        \"frage\",\n",
    "        \"nachricht\",\n",
    "        \"freundlich\",\n",
    "        \"sollen\",\n",
    "        \"müssen\",\n",
    "        \"mehr\",\n",
    "        \"grüße\",\n",
    "        \"daher\",\n",
    "        \"immer\",\n",
    "        \"dafür\"\n",
    "    ]\n",
    "    text = text.split()\n",
    "    text = [w for w in text if w not in individual_stopwords]\n",
    "    \n",
    "    return \" \".join(text)\n",
    "\n",
    "df_merged[\"clean_answer\"] = df_merged[\"clean_answer\"].apply(remove_individual_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43       name person groß bedeutung eigen identität ind...\n",
       "68       bürokratiekostenindex wichtig maß erfassung bü...\n",
       "106      namensrecht bundestag änderung ehenamen geburt...\n",
       "112      eckpunktepapier reform abstammungsrecht veröff...\n",
       "143      seit anfang unionsbürgerinn unionsbürger sowie...\n",
       "                               ...                        \n",
       "45894    verhandlungsbereitschaft erkennbar gegenteil h...\n",
       "45924    natürlich michael bloss gesetz wiederherstellu...\n",
       "45945    genau beschreiben kontrolle bedeuten direkt ko...\n",
       "45974    frei demokrat stehen freiheit einzeln mensch v...\n",
       "45988    nature restoration law letzter woche europäisc...\n",
       "Name: clean_answer, Length: 1686, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"clean_answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
