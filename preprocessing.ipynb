{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix encoding problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106012"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"data/abgeordnetenwatch_data_long.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45642"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data.dropna(subset=\"answer\")\n",
    "df_data = df_data.drop_duplicates(subset=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_csv(\"data/stratified_sample.csv\", sep=\";\")\n",
    "df_sample = df_sample.drop_duplicates(subset=\"answer\")\n",
    "df_sample = df_sample.dropna(subset=[\"answer\", \"answer_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_data, df_sample, on=\"question_id\", how=\"left\")\n",
    "df_merged = df_merged[[\"party_x\", \"last_name_x\", \"gender_x\", \"answer_x\", \"topic_x\", \"question_text_x\", \"question_teaser_x\", \"answer_encoded\"]]\n",
    "df_merged = df_merged.dropna(subset=\"answer_encoded\")\n",
    "df_merged.rename(columns={\n",
    "    \"party_x\" : \"party\",\n",
    "    \"last_name_x\" : \"last_name\",\n",
    "    \"gender_x\" : \"gender\",\n",
    "    \"answer_x\" : \"answer\",\n",
    "    \"topic_x\" : \"topic\",\n",
    "    \"question_text_x\" : \"question_text\",\n",
    "    \"question_teaser_x\" : \"question_teaser\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def text_lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_punct]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # remove links, punctuation, special letters\n",
    "    text = re.sub(r\"[^a-zA-öZÖäÄüÜß]|\\bhttps?://\\S*|&\\w+;|[\\.,]\", \" \", text)\n",
    "    \n",
    "    # replace single characters\n",
    "    text = re.sub(r\" [a-zA-Z] \", \" \", text)\n",
    "    \n",
    "    # remove additional whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lemmatize texts\n",
    "    text = text_lemmatization(text)\n",
    "\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # tokenization of words\n",
    "    text = text.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    german_stopwords = set(stopwords.words(\"german\"))\n",
    "    text = [w for w in text if w not in german_stopwords]\n",
    "    \n",
    "    # return joined text\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"clean_answer\"] = df_merged[\"answer\"].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43       geehrt frau vieler dank anfrage name person gr...\n",
       "68       geehrt herr vieler dank anfrage bürokratiekost...\n",
       "105      geehrt frau vieler dank anfrage namensrecht bu...\n",
       "111      geehrt frau vieler dank anfrage eckpunktepapie...\n",
       "142      geehrt herr vieler dank anfrage seit anfang un...\n",
       "                               ...                        \n",
       "45518    verhandlungsbereitschaft erkennbar gegenteil i...\n",
       "45548    danke frage natürlich michael bloss gesetz wie...\n",
       "45569    genau beschreiben kontrolle bedeuten direkt ko...\n",
       "45598    geehrt herr vieler dank frage frei demokrat st...\n",
       "45612    geehrt frau vieler dank nachricht frage nature...\n",
       "Name: clean_answer, Length: 1669, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"clean_answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
