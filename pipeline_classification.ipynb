{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import fasttext.util\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline für Textklassifikation mit fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "sample = pd.read_csv(\"data/labeled_unprocessed_sample_data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove possible missing values and duplicates\n",
    "sample = sample.dropna()\n",
    "sample = sample.drop_duplicates(subset=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def text_lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_punct]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # remove links, punctuation, special letters\n",
    "    text = re.sub(r\"[^a-zA-öZÖäÄüÜß]|\\bhttps?://\\S*|&\\w+;|[\\.,]\", \" \", text)\n",
    "    \n",
    "    # replace single characters\n",
    "    text = re.sub(r\" [a-zA-Z] \", \" \", text)\n",
    "    \n",
    "    # remove additional whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lemmatize texts\n",
    "    text = text_lemmatization(text)\n",
    "\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # tokenization of words\n",
    "    text = text.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    german_stopwords = set(stopwords.words(\"german\"))\n",
    "    text = [w for w in text if w not in german_stopwords]\n",
    "    \n",
    "    # return joined text\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"clean_answer\"] = sample[\"answer\"].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequencies</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9221</th>\n",
       "      <td>2012</td>\n",
       "      <td>geehrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>1718</td>\n",
       "      <td>freundlich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24838</th>\n",
       "      <td>1712</td>\n",
       "      <td>vieler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>1698</td>\n",
       "      <td>herr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>1579</td>\n",
       "      <td>frage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>1279</td>\n",
       "      <td>dank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20807</th>\n",
       "      <td>971</td>\n",
       "      <td>sollen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15637</th>\n",
       "      <td>942</td>\n",
       "      <td>mensch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9138</th>\n",
       "      <td>900</td>\n",
       "      <td>geben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10810</th>\n",
       "      <td>898</td>\n",
       "      <td>gut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>894</td>\n",
       "      <td>jahr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16363</th>\n",
       "      <td>842</td>\n",
       "      <td>müssen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>814</td>\n",
       "      <td>deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15536</th>\n",
       "      <td>794</td>\n",
       "      <td>mehr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8645</th>\n",
       "      <td>755</td>\n",
       "      <td>frau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25599</th>\n",
       "      <td>664</td>\n",
       "      <td>weit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>654</td>\n",
       "      <td>bundestag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>646</td>\n",
       "      <td>deutsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>582</td>\n",
       "      <td>dafür</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14313</th>\n",
       "      <td>577</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequencies        index\n",
       "9221          2012       geehrt\n",
       "8766          1718   freundlich\n",
       "24838         1712       vieler\n",
       "11383         1698         herr\n",
       "8594          1579        frage\n",
       "4977          1279         dank\n",
       "20807          971       sollen\n",
       "15637          942       mensch\n",
       "9138           900        geben\n",
       "10810          898          gut\n",
       "12650          894         jahr\n",
       "16363          842       müssen\n",
       "5287           814  deutschland\n",
       "15536          794         mehr\n",
       "8645           755         frau\n",
       "25599          664         weit\n",
       "4465           654    bundestag\n",
       "5284           646      deutsch\n",
       "4943           582        dafür\n",
       "14313          577         land"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show most frequent words\n",
    "vectorizer = CountVectorizer(\n",
    ")\n",
    "dtm = vectorizer.fit_transform(sample[\"clean_answer\"])\n",
    "\n",
    "frequencies = dtm.sum(axis=0).tolist()[0]\n",
    "\n",
    "df_freq = pd.DataFrame(\n",
    "    dict(frequencies=frequencies,\n",
    "         index=vectorizer.get_feature_names_out()\n",
    "    )\n",
    ")\n",
    "\n",
    "df_freq.sort_values(\"frequencies\", ascending=False).head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords with refined list and after lemmatization to catch \n",
    "def remove_individual_stopwords(text):\n",
    "    individual_stopwords = [\n",
    "        \"geehrt\",\n",
    "        \"frau\",\n",
    "        \"vieler\",\n",
    "        \"dank\",\n",
    "        \"herr\",\n",
    "        \"danke\",\n",
    "        \"anfrage\",\n",
    "        \"frage\",\n",
    "        \"nachricht\",\n",
    "        \"freundlich\",\n",
    "        \"sollen\",\n",
    "        \"müssen\",\n",
    "        \"mehr\",\n",
    "        \"grüße\",\n",
    "        \"daher\",\n",
    "        \"immer\",\n",
    "        \"dafür\",\n",
    "        \"frage\"\n",
    "    ]\n",
    "    text = text.split()\n",
    "    text = [w for w in text if w not in individual_stopwords]\n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"clean_answer\"] = sample[\"clean_answer\"].apply(remove_individual_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for processing by fasttext\n",
    "sample[\"answer_encoded\"] = sample[\"answer_encoded\"].apply(lambda x: x.replace(\" \", \"_\"))\n",
    "sample[\"answer_encoded\"] = sample[\"answer_encoded\"].apply(lambda x: \"__label__\" + x)\n",
    "sample[\"answer_encoding_combined\"] = sample[\"answer_encoded\"]+ \" \" + sample[\"clean_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate sample data into training, test and validation sets (80/10/10)\n",
    "training_sample, temp_df = train_test_split(sample, test_size=0.2, random_state=42)\n",
    "testing_sample, validation_sample = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export datasets\n",
    "training_sample[\"answer_encoding_combined\"].to_csv(\"data/training_data.csv\", index=False, header=False, sep=\";\")\n",
    "testing_sample[\"answer_encoding_combined\"].to_csv(\"data/testing_data.csv\", index=False, header=False, sep=\";\")\n",
    "validation_sample[\"answer_encoding_combined\"].to_csv(\"data/validation_data.csv\", index=False, header=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelltraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ohne optimierte Hyperparamater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model without optimizing the hyperparameter\n",
    "ft_model = fasttext.train_supervised(input=\"data/training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 0.6578947368421053, 0.6578947368421053)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "ft_model.test(\"data/testing_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mit optimierten Hyperparametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with optimizing the hyperparameter\n",
    "ft_model_optimized = fasttext.train_supervised(\n",
    "    input=\"data/training_data.csv\", \n",
    "    autotuneValidationFile=\"data/validation_data.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 0.6754385964912281, 0.6754385964912281)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "ft_model_optimized.test(\"data/testing_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testergebnisse für Label \"answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.678391959798995,\n",
       " 'recall': 0.9310344827586207,\n",
       " 'f1score': 0.7848837209302325}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model for label \"answer\"\n",
    "ft_model_optimized.test_label(\"data/testing_data.csv\")[\"__label__answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testergebnisse für Label \"evasive answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6551724137931034,\n",
       " 'recall': 0.2289156626506024,\n",
       " 'f1score': 0.3392857142857143}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model for label \"evasive answer\"\n",
    "ft_model_optimized.test_label(\"data/testing_data.csv\")[\"__label__evasive_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "ft_model_optimized.save_model(\"model/classification.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellanwendung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden und Vorverarbeiten der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unprocessed data without sample\n",
    "data = pd.read_csv(\"data/data_without_sample.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na and duplicates in answers\n",
    "data = data.drop_duplicates(subset=[\"answer\", \"question_text\"])\n",
    "data = data.dropna(subset=[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply text cleaning\n",
    "data[\"clean_answer\"] = data[\"answer\"].apply(text_preprocessing)\n",
    "data[\"clean_answer\"] = data[\"clean_answer\"].apply(remove_individual_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatisches Labeln der Antworten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract answers from colums\n",
    "text = data[\"clean_answer\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict label and probability of label for each answer\n",
    "labels, probalities = ft_model_optimized.predict(text, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nachbearbeiten der Labels und Probabilities für bessere Lesbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(list):\n",
    "    flattened_list = []\n",
    "    for item in list:\n",
    "        for i in item:\n",
    "            flattened_list.append(i)\n",
    "    return flattened_list\n",
    "\n",
    "flattened_labels = flatten_list(labels)\n",
    "flattened_probabilities = flatten_list(probalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append labels and probabilities to dataframe\n",
    "data[\"label\"] = flattened_labels\n",
    "data[\"probability\"] = flattened_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"] = data[\"label\"].apply(lambda x: x.replace(\"__label__\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>answer</th>\n",
       "      <th>topic</th>\n",
       "      <th>question_text</th>\n",
       "      <th>question_teaser</th>\n",
       "      <th>answer_encoded</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>label</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDP</td>\n",
       "      <td>Buschmann</td>\n",
       "      <td>m</td>\n",
       "      <td>Sehr geehrter Herr G., haben Sie vielen Dank f...</td>\n",
       "      <td>Bildung und Erziehung</td>\n",
       "      <td>Gerichte entscheiden fast ausschließlich gegen...</td>\n",
       "      <td>Wie wollen Sie das Wechselmodell stärker förd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brauchen familienrecht höhe zeit zählen insbes...</td>\n",
       "      <td>answer</td>\n",
       "      <td>0.796268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDP</td>\n",
       "      <td>Buschmann</td>\n",
       "      <td>m</td>\n",
       "      <td>Sehr geehrter Herr S., haben Sie vielen Dank f...</td>\n",
       "      <td>Recht</td>\n",
       "      <td>Sehr geehrter Herr Buschmann,ich beziehe mich ...</td>\n",
       "      <td>Wieso wird die tatsächliche Postlaufzeit um 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neufassung abs postg heben durchschnittlich br...</td>\n",
       "      <td>answer</td>\n",
       "      <td>0.742809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDP</td>\n",
       "      <td>Buschmann</td>\n",
       "      <td>m</td>\n",
       "      <td>Sehr geehrter Herr E.,haben Sie vielen Dank fü...</td>\n",
       "      <td>Soziale Sicherung</td>\n",
       "      <td>Zur vorherigen Frage eine Berichtigung: Das Sc...</td>\n",
       "      <td>Das Schonvermögen darf man selbstverständlich...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>klar wer freiwillig arbeiten netto brutto wer ...</td>\n",
       "      <td>answer</td>\n",
       "      <td>0.798249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDP</td>\n",
       "      <td>Buschmann</td>\n",
       "      <td>m</td>\n",
       "      <td>Sehr geehrter Herr D.,haben Sie vielen Dank fü...</td>\n",
       "      <td>Lobbyismus &amp; Transparenz</td>\n",
       "      <td>Sehr geehrter Herr Buschmann.Obwohl höchsten R...</td>\n",
       "      <td>Das Weisungsrecht gegenüber der Exekutive: Ob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>klar unabhängigkeit justiz wesentlich baustein...</td>\n",
       "      <td>answer</td>\n",
       "      <td>0.733446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDP</td>\n",
       "      <td>Buschmann</td>\n",
       "      <td>m</td>\n",
       "      <td>Sehr geehrte Frau S.,haben Sie vielen Dank für...</td>\n",
       "      <td>Landwirtschaft und Ernährung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anbindehaltung, Ferkelstände , wann wird dies...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frei demokrat treten verantwortungsvoll haltun...</td>\n",
       "      <td>answer</td>\n",
       "      <td>0.642618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  party  last_name gender                                             answer  \\\n",
       "0   FDP  Buschmann      m  Sehr geehrter Herr G., haben Sie vielen Dank f...   \n",
       "1   FDP  Buschmann      m  Sehr geehrter Herr S., haben Sie vielen Dank f...   \n",
       "2   FDP  Buschmann      m  Sehr geehrter Herr E.,haben Sie vielen Dank fü...   \n",
       "3   FDP  Buschmann      m  Sehr geehrter Herr D.,haben Sie vielen Dank fü...   \n",
       "4   FDP  Buschmann      m  Sehr geehrte Frau S.,haben Sie vielen Dank für...   \n",
       "\n",
       "                          topic  \\\n",
       "0         Bildung und Erziehung   \n",
       "1                         Recht   \n",
       "2             Soziale Sicherung   \n",
       "3      Lobbyismus & Transparenz   \n",
       "4  Landwirtschaft und Ernährung   \n",
       "\n",
       "                                       question_text  \\\n",
       "0  Gerichte entscheiden fast ausschließlich gegen...   \n",
       "1  Sehr geehrter Herr Buschmann,ich beziehe mich ...   \n",
       "2  Zur vorherigen Frage eine Berichtigung: Das Sc...   \n",
       "3  Sehr geehrter Herr Buschmann.Obwohl höchsten R...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                     question_teaser  answer_encoded  \\\n",
       "0   Wie wollen Sie das Wechselmodell stärker förd...             NaN   \n",
       "1   Wieso wird die tatsächliche Postlaufzeit um 2...             NaN   \n",
       "2   Das Schonvermögen darf man selbstverständlich...             NaN   \n",
       "3   Das Weisungsrecht gegenüber der Exekutive: Ob...             NaN   \n",
       "4   Anbindehaltung, Ferkelstände , wann wird dies...             NaN   \n",
       "\n",
       "                                        clean_answer   label  probability  \n",
       "0  brauchen familienrecht höhe zeit zählen insbes...  answer     0.796268  \n",
       "1  neufassung abs postg heben durchschnittlich br...  answer     0.742809  \n",
       "2  klar wer freiwillig arbeiten netto brutto wer ...  answer     0.798249  \n",
       "3  klar unabhängigkeit justiz wesentlich baustein...  answer     0.733446  \n",
       "4  frei demokrat treten verantwortungsvoll haltun...  answer     0.642618  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
